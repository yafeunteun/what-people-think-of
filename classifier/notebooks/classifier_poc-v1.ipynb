{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step : loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading/unpacking nltk\n",
      "  Downloading nltk-3.2.1.tar.gz (1.1MB): 1.1MB downloaded\n",
      "  Running setup.py (path:/tmp/pip_build_root/nltk/setup.py) egg_info for package nltk\n",
      "    \n",
      "    warning: no files found matching 'README.txt'\n",
      "    warning: no files found matching 'Makefile' under directory '*.txt'\n",
      "    warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "Installing collected packages: nltk\n",
      "  Running setup.py install for nltk\n",
      "    \n",
      "    warning: no files found matching 'README.txt'\n",
      "    warning: no files found matching 'Makefile' under directory '*.txt'\n",
      "    warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "Successfully installed nltk\n",
      "Cleaning up...\n",
      "[nltk_data] Downloading collection u'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package brown to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package floresta to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package nps_chat to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pil to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package propbank to /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package ptb to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package qc to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package rte to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package semcor to /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package timit to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package webtext to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | Downloading package rslp to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package hmm_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/hmm_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package panlex_lite to\n",
      "[nltk_data]    |     /home/ds/nltk_data...\n",
      "^CTraceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/nltk/downloader.py\", line 2268, in <module>\n",
      "\n",
      "    halt_on_error=options.halt_on_error)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/nltk/downloader.py\", line 664, in download\n",
      "    for msg in self.incr_download(info_or_id, download_dir, force):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/nltk/downloader.py\", line 543, in incr_download\n",
      "    for msg in self.incr_download(info.children, download_dir, force):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/nltk/downloader.py\", line 529, in incr_download\n",
      "    for msg in self._download_list(info_or_id, download_dir, force):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/nltk/downloader.py\", line 572, in _download_list\n",
      "    for msg in self.incr_download(item, download_dir, force):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/nltk/downloader.py\", line 549, in incr_download\n",
      "    for msg in self._download_package(info, download_dir, force):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/nltk/downloader.py\", line 618, in _download_package\n",
      "    s = infile.read(1024*16) # 16k blocks.\n",
      "  File \"/usr/lib/python2.7/socket.py\", line 380, in read\n",
      "    data = self._sock.recv(left)\n",
      "  File \"/usr/lib/python2.7/httplib.py\", line 573, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"/usr/lib/python2.7/socket.py\", line 380, in read\n",
      "    data = self._sock.recv(left)\n",
      "  File \"/usr/lib/python2.7/ssl.py\", line 341, in recv\n",
      "    return self.read(buflen)\n",
      "  File \"/usr/lib/python2.7/ssl.py\", line 260, in read\n",
      "    return self._sslobj.read(len)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install nltk\n",
    "!sudo python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ds/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading corpora: Package 'corpora' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/cleaned.tsv\", sep= \"\\t\", header=None, names=[\"id\", \"sentiment\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           1334228\n",
       "sentiment    1334228\n",
       "text         1334228\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"sentiment\"] == \"positive\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = data[data[\"sentiment\"] == \"positive\"].sample(6800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg = data[data[\"sentiment\"] == \"negative\"].sample(6800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neu = data[data[\"sentiment\"] == \"neutral\"].sample(6800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800\n",
      "6800\n",
      "6800\n"
     ]
    }
   ],
   "source": [
    "print len(pos)\n",
    "print len(neg)\n",
    "print len(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    return [wordnet_lemmatizer.lemmatize(word.lower()) for word in word_tokenize(sentence.decode('utf-8'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat = pd.concat([pos, neg, neu]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the text by white spaces and punctuation marks – the tools that are used for this purpose are called tokenizers, and you can use a tokenizer provided with the NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1383809</th>\n",
       "      <td>790558958679302144</td>\n",
       "      <td>positive</td>\n",
       "      <td>@matthewlau18 @Jeraldawj trade for mb ;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825340</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@TheEconomist  It appears Polls will return to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826728</th>\n",
       "      <td>790153184236961792</td>\n",
       "      <td>positive</td>\n",
       "      <td>Post scene… Lovely bruises :) https://t.co/lCW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188372</th>\n",
       "      <td>790398248418553856</td>\n",
       "      <td>negative</td>\n",
       "      <td>All i want in life is to hug a panda :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720396</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>griersunflower  https://t.co/GJbCxZpZt1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id sentiment  \\\n",
       "1383809  790558958679302144  positive   \n",
       "1825340         unavailable   neutral   \n",
       "826728   790153184236961792  positive   \n",
       "1188372  790398248418553856  negative   \n",
       "1720396         unavailable   neutral   \n",
       "\n",
       "                                                      text  \n",
       "1383809           @matthewlau18 @Jeraldawj trade for mb ;)  \n",
       "1825340  @TheEconomist  It appears Polls will return to...  \n",
       "826728   Post scene… Lovely bruises :) https://t.co/lCW...  \n",
       "1188372            All i want in life is to hug a panda :(  \n",
       "1720396            griersunflower  https://t.co/GJbCxZpZt1  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = lambda x: nltk.word_tokenize(x.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat[\"text\"] = dat[\"text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1383809</th>\n",
       "      <td>790558958679302144</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, matthewlau18, @, jeraldawj, trade, for, mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825340</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, theeconomist, it, appears, poll, will, ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826728</th>\n",
       "      <td>790153184236961792</td>\n",
       "      <td>positive</td>\n",
       "      <td>[post, scene…, lovely, bruise, :, ), http, :, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188372</th>\n",
       "      <td>790398248418553856</td>\n",
       "      <td>negative</td>\n",
       "      <td>[all, i, want, in, life, is, to, hug, a, panda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720396</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[griersunflower, http, :, //t.co/gjbcxzpzt1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id sentiment  \\\n",
       "1383809  790558958679302144  positive   \n",
       "1825340         unavailable   neutral   \n",
       "826728   790153184236961792  positive   \n",
       "1188372  790398248418553856  negative   \n",
       "1720396         unavailable   neutral   \n",
       "\n",
       "                                                      text  \n",
       "1383809  [@, matthewlau18, @, jeraldawj, trade, for, mb...  \n",
       "1825340  [@, theeconomist, it, appears, poll, will, ret...  \n",
       "826728   [post, scene…, lovely, bruise, :, ), http, :, ...  \n",
       "1188372  [all, i, want, in, life, is, to, hug, a, panda...  \n",
       "1720396       [griersunflower, http, :, //t.co/gjbcxzpzt1]  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linking the different forms of the same word (for example, price and prices, is and are) to each other – the tools that can do that are called lemmatizers, and you can again use one of those that come with the NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting all words to lowercase so that the classifier does not treat People, people and PEOPLE as three separate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1383809</th>\n",
       "      <td>790558958679302144</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, matthewlau18, @, jeraldawj, trade, for, mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825340</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, theeconomist, it, appears, poll, will, ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826728</th>\n",
       "      <td>790153184236961792</td>\n",
       "      <td>positive</td>\n",
       "      <td>[post, scene…, lovely, bruise, :, ), http, :, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188372</th>\n",
       "      <td>790398248418553856</td>\n",
       "      <td>negative</td>\n",
       "      <td>[all, i, want, in, life, is, to, hug, a, panda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720396</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[griersunflower, http, :, //t.co/gjbcxzpzt1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537744</th>\n",
       "      <td>789904006978035713</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, keplermessiah, @, maggyw519, @, ejlandwehr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525166</th>\n",
       "      <td>790636482532958208</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, everythingrobyn, @, seattlegators, we, 'd,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704587</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[happy, birthday, !, !, !, wish, u, many, more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69935</th>\n",
       "      <td>782720905566838784</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, hh_kevriel91, thanks, for, welcoming, ,, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717237</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[kai, is, not, a, good, guy, ., he, is, not, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080498</th>\n",
       "      <td>790323399147085824</td>\n",
       "      <td>negative</td>\n",
       "      <td>[i, miss, my, cat, :, (]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463491</th>\n",
       "      <td>790602929061462017</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sem, wpp, again, :, (]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80929</th>\n",
       "      <td>782751289163837444</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, nusavp, your, graphic, would, of, been, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663213</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, bmacrunning, some, positive, learning, poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628394</th>\n",
       "      <td>789967998031306752</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, it, wa, just, a, dream.., but, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021702</th>\n",
       "      <td>790283953995341824</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, funselman, @, poms_polls_, no, vote, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696164</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, time, @, cairnstoon, bosch, revisited]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98010</th>\n",
       "      <td>782797032507531265</td>\n",
       "      <td>negative</td>\n",
       "      <td>[i, will, never, understand, why, a, person, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708095</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[grand, release, tmrw, http, :, //t.co/2xybzjf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598030</th>\n",
       "      <td>789944930194120708</td>\n",
       "      <td>negative</td>\n",
       "      <td>[just, one, more, block, ..., :, (, @, joeyv1262]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619484</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, shelbyzahn4, i, have, one, &amp;, amp, ;, i, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270714</th>\n",
       "      <td>783405632955289600</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ask, or, tell, me, something, !, http, :, //t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731454</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[i, want, to, be, part, of, this, group, http,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702457</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[., @, wmesloub, a, fav, http, :, //t.co/2tmq8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877533</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ca, n't, believe, that, tonight, is, our, las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533856</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, kaysoclearn, @, _mrs_b, tried, something, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708495</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[thatssonicola, http, :, //t.co/wriue531is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733369</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, huffingtonpost, @, potus, you, do, n't, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730909</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, nytimes, @, realdonaldtrump, ..., take, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075950</th>\n",
       "      <td>790320096375869440</td>\n",
       "      <td>positive</td>\n",
       "      <td>[this, is, how, we, met, :, ), bouthut, wa, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677522</th>\n",
       "      <td>790008923944136704</td>\n",
       "      <td>negative</td>\n",
       "      <td>[can, someone, get, me, food, :, (]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391490</th>\n",
       "      <td>790563390749937664</td>\n",
       "      <td>negative</td>\n",
       "      <td>[i, need, to, go, back, to, sleep, before, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145107</th>\n",
       "      <td>790368767943389185</td>\n",
       "      <td>negative</td>\n",
       "      <td>[regret, ., :, (]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726935</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, time, @, lifemotto, who, give, a, shit, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185014</th>\n",
       "      <td>790395668971999233</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, brandonrambles, it, suck, :, (]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488388</th>\n",
       "      <td>789873032294649856</td>\n",
       "      <td>positive</td>\n",
       "      <td>[gon, na, be, live, streaming, the, beta, in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472404</th>\n",
       "      <td>789862892522840065</td>\n",
       "      <td>negative</td>\n",
       "      <td>[huge, midterm, tomorrow, and, only, done, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702620</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[omg, !, !, !, !, !, !, 💖💖💖💖, (, mia, :, carol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759335</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, indigo6e, we, started, this, year, with, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221629</th>\n",
       "      <td>790425604076236800</td>\n",
       "      <td>positive</td>\n",
       "      <td>[#, nycc2016, #, rwby, photoshoot, in, 360°, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705320</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, nytimes, @, nytopinion, this, u, marine, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728543</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, time, //, ., they, are, not, republican, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192838</th>\n",
       "      <td>790401732677251072</td>\n",
       "      <td>positive</td>\n",
       "      <td>[baked, fiend, on, toast, (, or, ghost, ), ;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979739</th>\n",
       "      <td>790258926646358016</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, bxrdergod, @, thevenixnetwork, gg, sorry, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374569</th>\n",
       "      <td>783633611580854272</td>\n",
       "      <td>positive</td>\n",
       "      <td>[hahaha, ., childhood, day, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554765</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, neillyfabi, best, advice, i, ever, gave, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708701</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[i, would, ., http, :, //t.co/ecd2m3eynr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069046</th>\n",
       "      <td>790315171893874688</td>\n",
       "      <td>positive</td>\n",
       "      <td>[#, coming, to, london, in, 2, day, #, need, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687788</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[queen, 😭😭😭😭😭💔💔💔💔, http, :, //t.co/5wjrnqrqsn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388395</th>\n",
       "      <td>783662892243677184</td>\n",
       "      <td>positive</td>\n",
       "      <td>[@, ellelazore, thanks, elle, :, )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030772</th>\n",
       "      <td>790289674111713292</td>\n",
       "      <td>negative</td>\n",
       "      <td>[lot, of, siren, and, dog, barking, ., at, lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270135</th>\n",
       "      <td>790475079427694593</td>\n",
       "      <td>positive</td>\n",
       "      <td>[hello, cipher, mao, (, ciphermao, ), :, ), ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692269</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[sorry, love, http, :, //t.co/dxsckyz76i]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491990</th>\n",
       "      <td>790619044923711488</td>\n",
       "      <td>negative</td>\n",
       "      <td>[i, 've, always, really, wanted, to, get, a, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862886</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>positive</td>\n",
       "      <td>[so, lucky, :, )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857022</th>\n",
       "      <td>790179845833650176</td>\n",
       "      <td>positive</td>\n",
       "      <td>[hmmm, ..., my, #, appleid, got, blocked, ...,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096169</th>\n",
       "      <td>790334994933833728</td>\n",
       "      <td>positive</td>\n",
       "      <td>[💧®x, wassup, bud, :, )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503174</th>\n",
       "      <td>789882219883933701</td>\n",
       "      <td>positive</td>\n",
       "      <td>[bollywood, is, derived, from, bombay, ., bomb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75440</th>\n",
       "      <td>782735858755473408</td>\n",
       "      <td>positive</td>\n",
       "      <td>[also, i, worked, an, 8, hour, shift, and, lef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690225</th>\n",
       "      <td>unavailable</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[cornyyyyyy, http, :, //t.co/b3pbzfaoto]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id sentiment  \\\n",
       "1383809  790558958679302144  positive   \n",
       "1825340         unavailable   neutral   \n",
       "826728   790153184236961792  positive   \n",
       "1188372  790398248418553856  negative   \n",
       "1720396         unavailable   neutral   \n",
       "537744   789904006978035713  positive   \n",
       "1525166  790636482532958208  positive   \n",
       "1704587         unavailable   neutral   \n",
       "69935    782720905566838784  positive   \n",
       "1717237         unavailable   neutral   \n",
       "1080498  790323399147085824  negative   \n",
       "1463491  790602929061462017  negative   \n",
       "80929    782751289163837444  negative   \n",
       "1663213         unavailable  positive   \n",
       "628394   789967998031306752  positive   \n",
       "1021702  790283953995341824  positive   \n",
       "1696164         unavailable   neutral   \n",
       "98010    782797032507531265  negative   \n",
       "1708095         unavailable   neutral   \n",
       "598030   789944930194120708  negative   \n",
       "1619484         unavailable  positive   \n",
       "270714   783405632955289600  negative   \n",
       "1731454         unavailable   neutral   \n",
       "1702457         unavailable   neutral   \n",
       "1877533         unavailable  negative   \n",
       "1533856         unavailable  negative   \n",
       "1708495         unavailable   neutral   \n",
       "1733369         unavailable   neutral   \n",
       "1730909         unavailable   neutral   \n",
       "1075950  790320096375869440  positive   \n",
       "...                     ...       ...   \n",
       "677522   790008923944136704  negative   \n",
       "1391490  790563390749937664  negative   \n",
       "1145107  790368767943389185  negative   \n",
       "1726935         unavailable   neutral   \n",
       "1185014  790395668971999233  negative   \n",
       "488388   789873032294649856  positive   \n",
       "472404   789862892522840065  negative   \n",
       "1702620         unavailable   neutral   \n",
       "1759335         unavailable  positive   \n",
       "1221629  790425604076236800  positive   \n",
       "1705320         unavailable   neutral   \n",
       "1728543         unavailable   neutral   \n",
       "1192838  790401732677251072  positive   \n",
       "979739   790258926646358016  negative   \n",
       "374569   783633611580854272  positive   \n",
       "1554765         unavailable  positive   \n",
       "1708701         unavailable   neutral   \n",
       "1069046  790315171893874688  positive   \n",
       "1687788         unavailable   neutral   \n",
       "388395   783662892243677184  positive   \n",
       "1030772  790289674111713292  negative   \n",
       "1270135  790475079427694593  positive   \n",
       "1692269         unavailable   neutral   \n",
       "1491990  790619044923711488  negative   \n",
       "1862886         unavailable  positive   \n",
       "857022   790179845833650176  positive   \n",
       "1096169  790334994933833728  positive   \n",
       "503174   789882219883933701  positive   \n",
       "75440    782735858755473408  positive   \n",
       "1690225         unavailable   neutral   \n",
       "\n",
       "                                                      text  \n",
       "1383809  [@, matthewlau18, @, jeraldawj, trade, for, mb...  \n",
       "1825340  [@, theeconomist, it, appears, poll, will, ret...  \n",
       "826728   [post, scene…, lovely, bruise, :, ), http, :, ...  \n",
       "1188372  [all, i, want, in, life, is, to, hug, a, panda...  \n",
       "1720396       [griersunflower, http, :, //t.co/gjbcxzpzt1]  \n",
       "537744   [@, keplermessiah, @, maggyw519, @, ejlandwehr...  \n",
       "1525166  [@, everythingrobyn, @, seattlegators, we, 'd,...  \n",
       "1704587  [happy, birthday, !, !, !, wish, u, many, more...  \n",
       "69935    [@, hh_kevriel91, thanks, for, welcoming, ,, k...  \n",
       "1717237  [kai, is, not, a, good, guy, ., he, is, not, a...  \n",
       "1080498                           [i, miss, my, cat, :, (]  \n",
       "1463491                            [sem, wpp, again, :, (]  \n",
       "80929    [@, nusavp, your, graphic, would, of, been, be...  \n",
       "1663213  [@, bmacrunning, some, positive, learning, poi...  \n",
       "628394   [i, thought, it, wa, just, a, dream.., but, wh...  \n",
       "1021702  [@, funselman, @, poms_polls_, no, vote, for, ...  \n",
       "1696164         [@, time, @, cairnstoon, bosch, revisited]  \n",
       "98010    [i, will, never, understand, why, a, person, c...  \n",
       "1708095  [grand, release, tmrw, http, :, //t.co/2xybzjf...  \n",
       "598030   [just, one, more, block, ..., :, (, @, joeyv1262]  \n",
       "1619484  [@, shelbyzahn4, i, have, one, &, amp, ;, i, w...  \n",
       "270714   [ask, or, tell, me, something, !, http, :, //t...  \n",
       "1731454  [i, want, to, be, part, of, this, group, http,...  \n",
       "1702457  [., @, wmesloub, a, fav, http, :, //t.co/2tmq8...  \n",
       "1877533  [ca, n't, believe, that, tonight, is, our, las...  \n",
       "1533856  [@, kaysoclearn, @, _mrs_b, tried, something, ...  \n",
       "1708495        [thatssonicola, http, :, //t.co/wriue531is]  \n",
       "1733369  [@, huffingtonpost, @, potus, you, do, n't, lo...  \n",
       "1730909  [@, nytimes, @, realdonaldtrump, ..., take, a,...  \n",
       "1075950  [this, is, how, we, met, :, ), bouthut, wa, tr...  \n",
       "...                                                    ...  \n",
       "677522                 [can, someone, get, me, food, :, (]  \n",
       "1391490  [i, need, to, go, back, to, sleep, before, i, ...  \n",
       "1145107                                  [regret, ., :, (]  \n",
       "1726935     [@, time, @, lifemotto, who, give, a, shit, ?]  \n",
       "1185014                [@, brandonrambles, it, suck, :, (]  \n",
       "488388   [gon, na, be, live, streaming, the, beta, in, ...  \n",
       "472404   [huge, midterm, tomorrow, and, only, done, wit...  \n",
       "1702620  [omg, !, !, !, !, !, !, 💖💖💖💖, (, mia, :, carol...  \n",
       "1759335  [@, indigo6e, we, started, this, year, with, y...  \n",
       "1221629  [#, nycc2016, #, rwby, photoshoot, in, 360°, w...  \n",
       "1705320  [@, nytimes, @, nytopinion, this, u, marine, w...  \n",
       "1728543  [@, time, //, ., they, are, not, republican, ,...  \n",
       "1192838  [baked, fiend, on, toast, (, or, ghost, ), ;, ...  \n",
       "979739   [@, bxrdergod, @, thevenixnetwork, gg, sorry, ...  \n",
       "374569                      [hahaha, ., childhood, day, !]  \n",
       "1554765  [@, neillyfabi, best, advice, i, ever, gave, a...  \n",
       "1708701          [i, would, ., http, :, //t.co/ecd2m3eynr]  \n",
       "1069046  [#, coming, to, london, in, 2, day, #, need, t...  \n",
       "1687788     [queen, 😭😭😭😭😭💔💔💔💔, http, :, //t.co/5wjrnqrqsn]  \n",
       "388395                 [@, ellelazore, thanks, elle, :, )]  \n",
       "1030772  [lot, of, siren, and, dog, barking, ., at, lea...  \n",
       "1270135  [hello, cipher, mao, (, ciphermao, ), :, ), ht...  \n",
       "1692269          [sorry, love, http, :, //t.co/dxsckyz76i]  \n",
       "1491990  [i, 've, always, really, wanted, to, get, a, f...  \n",
       "1862886                                  [so, lucky, :, )]  \n",
       "857022   [hmmm, ..., my, #, appleid, got, blocked, ...,...  \n",
       "1096169                           [💧®x, wassup, bud, :, )]  \n",
       "503174   [bollywood, is, derived, from, bombay, ., bomb...  \n",
       "75440    [also, i, worked, an, 8, hour, shift, and, lef...  \n",
       "1690225           [cornyyyyyy, http, :, //t.co/b3pbzfaoto]  \n",
       "\n",
       "[20400 rows x 3 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoplist = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_stop_words = [\"@\", \"rt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_stop_word = lambda list_of_words: [word for word in list_of_words if word not in stoplist+twitter_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_word([\"a\", \"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat[\"text\"] = dat[\"text\"].apply(remove_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(text, setting):\n",
    "    if setting=='bow':\n",
    "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist}\n",
    "    else:\n",
    "        return {word: True for word in preprocess(text) if not word in stoplist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = [(get_features(email, 'bow'), label) for (email, label) in all_emails]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
